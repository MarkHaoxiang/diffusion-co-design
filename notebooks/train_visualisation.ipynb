{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from IPython.display import Video\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from gymnasium.utils.save_video import save_video\n",
    "from torchrl.envs import EnvBase\n",
    "from diffusion_co_design.rware.env import create_env\n",
    "from diffusion_co_design.rware.model import rware_models\n",
    "from diffusion_co_design.utils import omega_to_pydantic, cuda, OUTPUT_DIR\n",
    "from diffusion_co_design.bin.train_rware import TrainingConfig, DesignerRegistry\n",
    "\n",
    "# Parameters\n",
    "training_dir = \"/home/markhaoxiang/.diffusion_co_design/training/2025-02-17/09-40-27\"\n",
    "device = cuda\n",
    "\n",
    "# Get latest policy\n",
    "checkpoint_dir = os.path.join(training_dir, \"checkpoints\")\n",
    "policy_files = [f for f in os.listdir(checkpoint_dir) if re.match(r\"policy_\\d+\\.pt\", f)]\n",
    "latest_policy = max(policy_files, key=lambda x: int(re.search(r\"\\d+\", x).group()))\n",
    "latest_policy = os.path.join(checkpoint_dir, latest_policy)\n",
    "\n",
    "# Get config\n",
    "hydra_dir = os.path.join(training_dir, \".hydra\")\n",
    "training_config = os.path.join(hydra_dir, \"config.yaml\")\n",
    "cfg = omega_to_pydantic(OmegaConf.load(training_config), TrainingConfig)\n",
    "\n",
    "# Create environment\n",
    "cache_dir = os.path.join(OUTPUT_DIR, \".tmp\")\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "os.makedirs(cache_dir)\n",
    "master_designer, env_designer = DesignerRegistry.get(\n",
    "    cfg.designer,\n",
    "    cfg.scenario,\n",
    "    cache_dir,\n",
    "    environment_batch_size=32,\n",
    "    device=device,\n",
    ")\n",
    "env = create_env(cfg.scenario, env_designer, render=True, device=device)\n",
    "policy, _ = rware_models(env, cfg.policy, device=device)\n",
    "policy.load_state_dict(torch.load(latest_policy))\n",
    "\n",
    "\n",
    "def view_video(env: EnvBase, policy):\n",
    "    frames = []\n",
    "    video_out = os.path.join(cache_dir, \"video/rl-video-episode-0.mp4\")\n",
    "\n",
    "    def append_frames(env, td):\n",
    "        return frames.append(env.render())\n",
    "\n",
    "    env.rollout(\n",
    "        max_steps=cfg.scenario.max_steps,\n",
    "        policy=policy,\n",
    "        callback=append_frames,\n",
    "        auto_cast_to_device=True,\n",
    "    )\n",
    "\n",
    "    save_video(\n",
    "        frames=frames,\n",
    "        video_folder=os.path.join(cache_dir, \"video\"),\n",
    "        fps=10,\n",
    "    )\n",
    "\n",
    "    return lambda: Video(filename=video_out, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_video(env, policy)()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
