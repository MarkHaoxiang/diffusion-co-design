{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusion_co_design.pretrain.rware.transform import storage_to_layout\n",
    "from diffusion_co_design.bin.train_rware import (\n",
    "    TrainingConfig,\n",
    "    DesignerRegistry,\n",
    "    DesignerConfig,\n",
    "    ScenarioConfig,\n",
    ")\n",
    "from diffusion_co_design.utils import (\n",
    "    omega_to_pydantic,\n",
    "    get_latest_model,\n",
    "    cuda,\n",
    ")\n",
    "from diffusion_co_design.rware.env import create_env\n",
    "from diffusion_co_design.rware.model import rware_models\n",
    "from diffusion_co_design.pretrain.rware.graph import WarehouseGNNBase, E3GNNLayer\n",
    "from rware.warehouse import Warehouse\n",
    "\n",
    "from dataset import load_dataset, CollateFn, working_dir\n",
    "\n",
    "device = cuda\n",
    "training_dir = \"/home/markhaoxiang/.diffusion_co_design/training/2025-04-05/04-00-12\"  # Four corners\n",
    "\n",
    "# Load latest model and config\n",
    "checkpoint_dir = os.path.join(training_dir, \"checkpoints\")\n",
    "latest_policy = get_latest_model(checkpoint_dir, \"policy_\")\n",
    "# Get config\n",
    "hydra_dir = os.path.join(training_dir, \".hydra\")\n",
    "cfg = omega_to_pydantic(\n",
    "    OmegaConf.load(os.path.join(hydra_dir, \"config.yaml\")), TrainingConfig\n",
    ")\n",
    "\n",
    "cfg.scenario.representation = \"image\"\n",
    "\n",
    "_, env_designer = DesignerRegistry.get(\n",
    "    DesignerConfig(type=\"random\"),\n",
    "    cfg.scenario,\n",
    "    working_dir,\n",
    "    environment_batch_size=32,\n",
    "    device=device,\n",
    ")\n",
    "env = create_env(cfg.scenario, env_designer, render=True, device=device)\n",
    "policy, _ = rware_models(env, cfg.policy, device=device)\n",
    "policy.load_state_dict(torch.load(latest_policy))\n",
    "\n",
    "# Make Dataset\n",
    "train_dataset, eval_dataset = load_dataset(\n",
    "    scenario=cfg.scenario,\n",
    "    policy=policy,\n",
    "    dataset_size=10_000,\n",
    "    num_workers=25,\n",
    "    test_proportion=0.2,\n",
    "    recompute=True,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a089b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "collate_fn = CollateFn(cfg.scenario, device)\n",
    "\n",
    "\n",
    "def make_dataloader(dataset, batch_size=128):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataloader = make_dataloader(train_dataset, batch_size=128)\n",
    "eval_dataloader = make_dataloader(eval_dataset, batch_size=128)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de938e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, cfg: ScenarioConfig, hidden_dim: int = 512, num_layers: int = 4):\n",
    "        super().__init__()\n",
    "        in_dim = (2 + cfg.n_colors) * cfg.n_shelves\n",
    "\n",
    "        layers = []\n",
    "        dims = [in_dim] + [hidden_dim] * (num_layers - 1)\n",
    "\n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            layers.append(nn.LayerNorm(dims[i + 1]))\n",
    "            layers.append(nn.SiLU())\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, pos, colors):\n",
    "        x = torch.cat([pos, colors], dim=-1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.net(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "\n",
    "model = MLPClassifier(cfg.scenario).to(device)\n",
    "\n",
    "# Test\n",
    "(pos, color), y = next(iter(train_dataloader))\n",
    "\n",
    "number_parameters = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Number of parameters: {number_parameters}\")\n",
    "assert model(pos, color).shape == y.shape\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11487407",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_EPOCHS = 100\n",
    "RECOMPUTE = True\n",
    "\n",
    "model = MLPClassifier(cfg.scenario).to(device)\n",
    "model_dir = os.path.join(working_dir, \"classifier_mlp.pt\")\n",
    "\n",
    "\n",
    "if RECOMPUTE or not os.path.exists(model_dir):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    with tqdm(range(TRAIN_NUM_EPOCHS)) as pbar:\n",
    "        for epoch in range(TRAIN_NUM_EPOCHS):\n",
    "            running_train_loss = 0\n",
    "            model.train()\n",
    "            for (pos, color), y in train_dataloader:\n",
    "                optim.zero_grad()\n",
    "\n",
    "                y_pred = model(pos, color)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "                running_train_loss += loss.item()\n",
    "            running_train_loss = running_train_loss / len(train_dataloader)\n",
    "\n",
    "            # Evaluate\n",
    "            model.eval()\n",
    "            running_eval_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for (pos, color), y in train_dataloader:\n",
    "                    y_pred = model(pos, color).squeeze()\n",
    "                    loss = criterion(y_pred, y)\n",
    "\n",
    "                    running_eval_loss += loss.item()\n",
    "            running_eval_loss = running_eval_loss / len(eval_dataloader)\n",
    "\n",
    "            train_losses.append(running_train_loss)\n",
    "            eval_losses.append(running_eval_loss)\n",
    "            pbar.set_description(\n",
    "                f\" Train Loss {running_train_loss} Eval Loss {running_eval_loss}\"\n",
    "            )\n",
    "            pbar.update()\n",
    "\n",
    "    torch.save(model.state_dict(), model_dir)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71991fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert train_losses is not None\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_losses, label=\"train\")\n",
    "    ax.plot(eval_losses, label=\"eval\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_title(\"Training Losses (MLP)\")\n",
    "    fig.legend()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "FIGURE_SIZE_CNST = 2.5\n",
    "\n",
    "env_returns_sorted_index = torch.argsort(eval_dataset[:][1], descending=True)\n",
    "# env_returns_sorted_index = torch.argsort(\n",
    "#     env_returns.storage[\"episode_reward\"], descending=True\n",
    "# )\n",
    "best_5 = env_returns_sorted_index[:5]\n",
    "worst_5 = env_returns_sorted_index[-5:]\n",
    "\n",
    "fig, axs = plt.subplots(2, 5)\n",
    "fig.set_size_inches(5 * FIGURE_SIZE_CNST, 2 * FIGURE_SIZE_CNST)\n",
    "\n",
    "for i, idx in enumerate(best_5):\n",
    "    ax = axs[0, i]\n",
    "    layout = storage_to_layout(\n",
    "        features=eval_dataset[:][0][idx].numpy(force=True),\n",
    "        config=cfg.scenario,\n",
    "    )\n",
    "    print(eval_dataset[:][1][idx])\n",
    "    warehouse = Warehouse(layout=layout, render_mode=\"rgb_array\")\n",
    "    im = warehouse.render()\n",
    "    ax.imshow(im)\n",
    "    warehouse.close()\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "print(\"===\")\n",
    "\n",
    "for i, idx in enumerate(worst_5):\n",
    "    ax = axs[1, i]\n",
    "    layout = storage_to_layout(\n",
    "        # env_returns.storage[\"env\"][idx],\n",
    "        features=eval_dataset[:][0][idx].numpy(force=True),\n",
    "        config=cfg.scenario,\n",
    "    )\n",
    "    print(eval_dataset[:][1][idx])\n",
    "    warehouse = Warehouse(layout=layout, render_mode=\"rgb_array\")\n",
    "    im = warehouse.render()\n",
    "    ax.imshow(im)\n",
    "    warehouse.close()\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c677a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layout = [next(iter(train_dataset))]\n",
    "test_layout, _ = collate_fn(test_layout)\n",
    "pos, color = test_layout\n",
    "\n",
    "pos.requires_grad = True\n",
    "pos_optim = torch.optim.Adam([pos], lr=0.01)\n",
    "\n",
    "\n",
    "n_iterations = 500\n",
    "for iteration in range(n_iterations):\n",
    "    pos_optim.zero_grad()\n",
    "    y_pred = model(pos, color)\n",
    "    loss = -y_pred.mean()\n",
    "    loss.backward()\n",
    "    pos_optim.step()\n",
    "\n",
    "    if iteration % (n_iterations // 10) == 0:\n",
    "        print(f\"Iteration {iteration} Loss: {loss.item()}\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(FIGURE_SIZE_CNST, FIGURE_SIZE_CNST))\n",
    "\n",
    "        show_pos = (pos.squeeze() + 1) / 2\n",
    "        show_pos = show_pos * cfg.scenario.size\n",
    "        layout = storage_to_layout(\n",
    "            features=show_pos.numpy(force=True),\n",
    "            config=cfg.scenario,\n",
    "            representation_override=\"graph\",\n",
    "        )\n",
    "        warehouse = Warehouse(layout=layout, render_mode=\"rgb_array\")\n",
    "        print(len(warehouse.shelves))\n",
    "        im = warehouse.render()\n",
    "        ax.imshow(im)\n",
    "        ax.axis(\"off\")\n",
    "        plt.show()\n",
    "        warehouse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ad4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphClassifier(WarehouseGNNBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        scenario: ScenarioConfig,\n",
    "        node_embedding_dim: int = 64,\n",
    "        edge_embedding_dim: int = 32,\n",
    "        num_layers: int = 5,\n",
    "        use_radius_graph: bool = True,\n",
    "        radius: float = 0.5,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            scenario=scenario,\n",
    "            use_radius_graph=use_radius_graph,\n",
    "            radius=radius,\n",
    "            include_color_features=True,\n",
    "        )\n",
    "\n",
    "        self.embedding_dim = node_embedding_dim\n",
    "        self.num_nodes = scenario.n_goals + scenario.n_shelves\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.h_in = nn.Linear(self.feature_dim, node_embedding_dim)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.convs.append(\n",
    "                E3GNNLayer(\n",
    "                    node_embedding_dim=node_embedding_dim,\n",
    "                    edge_embedding_dim=edge_embedding_dim,\n",
    "                    graph_embedding_dim=0,  # no timestep embeddings\n",
    "                    update_node_features=i < num_layers - 1,\n",
    "                    use_attention=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.readout = global_add_pool\n",
    "        self.out_mlp = nn.Sequential(\n",
    "            nn.Linear(node_embedding_dim, node_embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(node_embedding_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, pos: torch.Tensor, color: torch.Tensor) -> torch.Tensor:\n",
    "        graph, _ = self.make_graph_from_data(pos, color=color)\n",
    "        h = self.h_in(graph.h)  # [N, d]\n",
    "        pos = graph.pos  # [N, 2]\n",
    "        batch = graph.batch  # [N]\n",
    "\n",
    "        for i, gnn in enumerate(self.convs):\n",
    "            h, pos = gnn(h, graph.edge_index, pos, None, batch)\n",
    "\n",
    "        # Readout across entire graph (goals + shelves)\n",
    "        graph_repr = self.readout(h, batch)\n",
    "        return self.out_mlp(graph_repr).squeeze(-1)\n",
    "\n",
    "\n",
    "model = GraphClassifier(cfg.scenario).to(device)\n",
    "\n",
    "# Test\n",
    "(pos, color), y = next(iter(train_dataloader))\n",
    "\n",
    "number_parameters = sum([p.numel() for p in model.parameters()])\n",
    "print(f\"Number of parameters: {number_parameters}\")\n",
    "assert model(pos, color).shape == y.shape\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c690a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_EPOCHS = 50\n",
    "RECOMPUTE = True\n",
    "\n",
    "model = GraphClassifier(cfg.scenario).to(device)\n",
    "model_dir = os.path.join(working_dir, \"classifier_gnn.pt\")\n",
    "\n",
    "\n",
    "if RECOMPUTE or not os.path.exists(model_dir):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    with tqdm(range(TRAIN_NUM_EPOCHS)) as pbar:\n",
    "        for epoch in range(TRAIN_NUM_EPOCHS):\n",
    "            running_train_loss = 0\n",
    "            model.train()\n",
    "            for (pos, colors), y in train_dataloader:\n",
    "                optim.zero_grad()\n",
    "\n",
    "                y_pred = model(pos, colors)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "                running_train_loss += loss.item()\n",
    "            running_train_loss = running_train_loss / len(train_dataloader)\n",
    "\n",
    "            # Evaluate\n",
    "            model.eval()\n",
    "            running_eval_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for (pos, colors), y in train_dataloader:\n",
    "                    y_pred = model(pos, colors).squeeze()\n",
    "                    loss = criterion(y_pred, y)\n",
    "\n",
    "                    running_eval_loss += loss.item()\n",
    "            running_eval_loss = running_eval_loss / len(eval_dataloader)\n",
    "\n",
    "            train_losses.append(running_train_loss)\n",
    "            eval_losses.append(running_eval_loss)\n",
    "            pbar.set_description(\n",
    "                f\" Train Loss {running_train_loss} Eval Loss {running_eval_loss}\"\n",
    "            )\n",
    "            pbar.update()\n",
    "\n",
    "    torch.save(model.state_dict(), model_dir)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
